{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import threading\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_i_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\"\n",
    "with_slash = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\'\"\n",
    "\n",
    "d_i_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\d-i\"\n",
    "with_slash4 = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\d-i\\'\"\n",
    "\n",
    "j_p_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\"\n",
    "with_slash2 = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\\'\"\n",
    "\n",
    "q_z_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\\q-z\"\n",
    "with_slash3 = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\\q-z\\'\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "df3 = pd.DataFrame()\n",
    "df4 = pd.DataFrame()\n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine two datasets\n",
    "def combine(dat1, dat2):\n",
    "    to_combine = [dat1, dat2]\n",
    "    return pd.concat(to_combine)\n",
    "\n",
    "\n",
    "def get_company_name(id):\n",
    "    msft = yf.Ticker(id)\n",
    "\n",
    "    company_name = msft.info['longName']\n",
    "    return company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258423\n"
     ]
    }
   ],
   "source": [
    "# function to loop through and open files\n",
    "def files_to_dataframe(directory_path, with_slash, df):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename == 'j-p'or filename == 'q-z' or filename == 'd-i':\n",
    "            continue\n",
    "        directory = with_slash[:-1]\n",
    "        path = directory + filename\n",
    "        with open(path, 'r') as file:\n",
    "            dat = pd.read_csv(file)\n",
    "        dat['company_id'] = filename[:len(filename)-4]\n",
    "        df = combine(df, dat)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# loops through the folder broken up into four threads that run concurently \n",
    "thread1 = threading.Thread(target=files_to_dataframe, args=(a_i_directory_path, with_slash, df))\n",
    "thread2 = threading.Thread(target=files_to_dataframe, args=(j_p_directory_path, with_slash2, df2))\n",
    "thread3 = threading.Thread(target=files_to_dataframe, args=(q_z_directory_path, with_slash3, df3))\n",
    "thread4 = threading.Thread(target=files_to_dataframe, args=(d_i_directory_path, with_slash4, df4))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "thread4.join()\n",
    "\n",
    "# combining the dataframes from each of the four threads\n",
    "df = combine(dataframes[0], dataframes[1])\n",
    "df2 = combine(dataframes[2], dataframes[3])\n",
    "df = combine(df, df2)\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "# df['company'] = df.apply(get_company_name, axis=1)\n",
    "# df.drop(columns=['company_id'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the biggest difference in the low and high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest difference in high to low is 53156.0 from Berkshire Hathaway Inc.\n",
      "The high was 468795.00 and the low was 415639.00\n",
      "The date was 27-10-2022\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== DATA ANALYSIS =========================================\n",
    "\n",
    "df['difference'] = df.apply(lambda x: x.High - x.Low, axis=1)\n",
    "\n",
    "max = df[\"difference\"].max()\n",
    "df.set_index(\"difference\", inplace=True)\n",
    "\n",
    "high = df.loc[max,'High']\n",
    "low = df.loc[max,'Low']\n",
    "company = get_company_name(df.loc[max,'company_id'])\n",
    "date = df.loc[max, 'Date']\n",
    "\n",
    "print(f\"The biggest difference in high to low is {max} from {company}\")\n",
    "print(f'The high was {high:.2f} and the low was {low:.2f}')\n",
    "print(f'The date was {date}')\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the largest difference by percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest difference by percent from high to low is 99.98492462247178 from Formcap Corp.\n",
      "The high was 1.99 and the low was 0.0003\n",
      "The date was 23-11-2020\n"
     ]
    }
   ],
   "source": [
    "df['percent_difference'] = df.apply(lambda x: (x.difference / x.High) * 100, axis=1)\n",
    "max = df['percent_difference'].max()\n",
    "\n",
    "df.set_index(\"percent_difference\", inplace=True)\n",
    "company = df.loc[max, 'company_id']\n",
    "high = df.loc[max, 'High']\n",
    "low = df.loc[max, 'Low']\n",
    "date = df.loc[max, 'Date']\n",
    "\n",
    "print(f\"The biggest difference by percent from high to low is {max} from {get_company_name(company)}\")\n",
    "print(f'The high was {high:.2f} and the low was {low:.4f}')\n",
    "print(f'The date was {date}')\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "# print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the oldest and newest date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Blake Dennett\\AppData\\Local\\Temp\\ipykernel_772\\4159101142.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The oldest date is 1970-01-04 00:00:00\n",
      "The newest date is 2022-12-12 00:00:00\n",
      "   percent_difference  difference       Date        Low       Open     Volume  \\\n",
      "0            5.540352    3.988998 2015-02-01  68.010002  69.000000  4218700.0   \n",
      "1            5.946712    4.240005 2015-05-01  67.059998  71.230003  4534700.0   \n",
      "2            7.309895    4.969997 2015-06-01  63.020000  67.930000  3749400.0   \n",
      "3            4.868190    3.250004 2015-07-01  63.509998  65.010002  2122600.0   \n",
      "4            3.673418    2.560005 2015-08-01  67.129997  67.949997  2510300.0   \n",
      "\n",
      "        High      Close  Adjusted Close company_id    yr  \n",
      "0  71.999001  70.400002       70.400002       QRVO  2015  \n",
      "1  71.300003  67.629997       67.629997       QRVO  2015  \n",
      "2  67.989998  64.669998       64.669998       QRVO  2015  \n",
      "3  66.760002  66.650002       66.650002       QRVO  2015  \n",
      "4  69.690002  67.690002       67.690002       QRVO  2015  \n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['yr'] = pd.DatetimeIndex(df['Date']).year\n",
    "oldest = df['Date'].min()\n",
    "newest = df['Date'].max()\n",
    "print(f' The oldest date is {oldest}')\n",
    "print(f'The newest date is {newest}')\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to Guess the Close"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r^2 is: 0.9999138806589019 and the RMSE is: 6645.893880489394\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'difference':' difference', 'percent_difference':' percent_difference'}, inplace=True)\n",
    "X = df[[' difference', ' percent_difference', 'High', 'Low', 'Open', 'Volume']]\n",
    "y = df['Close']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "reg = GradientBoostingRegressor(random_state=25)\n",
    "reg.fit(x_train, y_train)\n",
    "y_predictions = reg.predict(x_test)\n",
    "r2 = r2_score(y_test, y_predictions)\n",
    "rmse = mean_squared_error(y_test, y_predictions)\n",
    "print(f'The r^2 is: {r2} and the RMSE is: {rmse}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\DataAnalysis\\DataAnalysis\\analysis.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Blake%20Dennett/Downloads/Spring2023/appliedProgramming/DataAnalysis/DataAnalysis/analysis.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m alt\u001b[39m.\u001b[39mdata_transformers\u001b[39m.\u001b[39mdisable_max_rows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
