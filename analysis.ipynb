{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import threading\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets\n",
    "\n",
    "a_i_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\"\n",
    "with_slash = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\'\"\n",
    "\n",
    "d_i_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\d-i\"\n",
    "with_slash4 = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\d-i\\'\"\n",
    "\n",
    "j_p_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\"\n",
    "with_slash2 = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\\'\"\n",
    "\n",
    "q_z_directory_path = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\\q-z\"\n",
    "with_slash3 = r\"C:\\Users\\Blake Dennett\\Downloads\\Spring2023\\appliedProgramming\\Data\\stock_market_data\\sp500\\csv\\j-p\\q-z\\'\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "df3 = pd.DataFrame()\n",
    "df4 = pd.DataFrame()\n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine two datasets\n",
    "def combine(dat1, dat2):\n",
    "    to_combine = [dat1, dat2]\n",
    "    return pd.concat(to_combine)\n",
    "\n",
    "\n",
    "def get_company_name(id):\n",
    "    msft = yf.Ticker(id)\n",
    "\n",
    "    company_name = msft.info['longName']\n",
    "    return company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258423\n"
     ]
    }
   ],
   "source": [
    "# function to loop through and open files\n",
    "def files_to_dataframe(directory_path, with_slash, df):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename == 'j-p'or filename == 'q-z' or filename == 'd-i':\n",
    "            continue\n",
    "        directory = with_slash[:-1]\n",
    "        path = directory + filename\n",
    "        with open(path, 'r') as file:\n",
    "            dat = pd.read_csv(file)\n",
    "        dat['company_id'] = filename[:len(filename)-4]\n",
    "        df = combine(df, dat)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# loops through the folder broken up into four threads that run concurently \n",
    "thread1 = threading.Thread(target=files_to_dataframe, args=(a_i_directory_path, with_slash, df))\n",
    "thread2 = threading.Thread(target=files_to_dataframe, args=(j_p_directory_path, with_slash2, df2))\n",
    "thread3 = threading.Thread(target=files_to_dataframe, args=(q_z_directory_path, with_slash3, df3))\n",
    "thread4 = threading.Thread(target=files_to_dataframe, args=(d_i_directory_path, with_slash4, df4))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "thread4.join()\n",
    "\n",
    "# combining the dataframes from each of the four threads\n",
    "df = combine(dataframes[0], dataframes[1])\n",
    "df2 = combine(dataframes[2], dataframes[3])\n",
    "df = combine(df, df2)\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "# df['company'] = df.apply(get_company_name, axis=1)\n",
    "# df.drop(columns=['company_id'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the biggest difference in the low and high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest difference in high to low is 53156.0 from Berkshire Hathaway Inc.\n",
      "The high was 468795.00 and the low was 415639.00\n",
      "The date was 27-10-2022\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== DATA ANALYSIS =========================================\n",
    "\n",
    "df['difference'] = df.apply(lambda x: x.High - x.Low, axis=1)\n",
    "\n",
    "max = df[\"difference\"].max()\n",
    "df.set_index(\"difference\", inplace=True)\n",
    "\n",
    "high = df.loc[max,'High']\n",
    "low = df.loc[max,'Low']\n",
    "company = get_company_name(df.loc[max,'company_id'])\n",
    "date = df.loc[max, 'Date']\n",
    "\n",
    "print(f\"The biggest difference in high to low is {max} from {company}\")\n",
    "print(f'The high was {high:.2f} and the low was {low:.2f}')\n",
    "print(f'The date was {date}')\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the largest difference by percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest difference by percent from high to low is 99.98492462247178 from Formcap Corp.\n",
      "The high was 1.99 and the low was 0.0003\n",
      "The date was 23-11-2020\n"
     ]
    }
   ],
   "source": [
    "df['percent_difference'] = df.apply(lambda x: (x.difference / x.High) * 100, axis=1)\n",
    "max = df['percent_difference'].max()\n",
    "\n",
    "df.set_index(\"percent_difference\", inplace=True)\n",
    "company = df.loc[max, 'company_id']\n",
    "high = df.loc[max, 'High']\n",
    "low = df.loc[max, 'Low']\n",
    "date = df.loc[max, 'Date']\n",
    "\n",
    "print(f\"The biggest difference by percent from high to low is {max} from {get_company_name(company)}\")\n",
    "print(f'The high was {high:.2f} and the low was {low:.4f}')\n",
    "print(f'The date was {date}')\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "# print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the oldest and newest date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Blake Dennett\\AppData\\Local\\Temp\\ipykernel_772\\4159101142.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The oldest date is 1970-01-04 00:00:00\n",
      "The newest date is 2022-12-12 00:00:00\n",
      "   percent_difference  difference       Date        Low       Open     Volume  \\\n",
      "0            5.540352    3.988998 2015-02-01  68.010002  69.000000  4218700.0   \n",
      "1            5.946712    4.240005 2015-05-01  67.059998  71.230003  4534700.0   \n",
      "2            7.309895    4.969997 2015-06-01  63.020000  67.930000  3749400.0   \n",
      "3            4.868190    3.250004 2015-07-01  63.509998  65.010002  2122600.0   \n",
      "4            3.673418    2.560005 2015-08-01  67.129997  67.949997  2510300.0   \n",
      "\n",
      "        High      Close  Adjusted Close company_id    yr  \n",
      "0  71.999001  70.400002       70.400002       QRVO  2015  \n",
      "1  71.300003  67.629997       67.629997       QRVO  2015  \n",
      "2  67.989998  64.669998       64.669998       QRVO  2015  \n",
      "3  66.760002  66.650002       66.650002       QRVO  2015  \n",
      "4  69.690002  67.690002       67.690002       QRVO  2015  \n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['yr'] = pd.DatetimeIndex(df['Date']).year\n",
    "oldest = df['Date'].min()\n",
    "newest = df['Date'].max()\n",
    "print(f' The oldest date is {oldest}')\n",
    "print(f'The newest date is {newest}')\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to Guess the Close"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r^2 is: 0.9999138806589019 and the RMSE is: 6645.893880489394\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'difference':' difference', 'percent_difference':' percent_difference'}, inplace=True)\n",
    "X = df[[' difference', ' percent_difference', 'High', 'Low', 'Open', 'Volume']]\n",
    "y = df['Close']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "reg = GradientBoostingRegressor(random_state=25)\n",
    "reg.fit(x_train, y_train)\n",
    "y_predictions = reg.predict(x_test)\n",
    "r2 = r2_score(y_test, y_predictions)\n",
    "rmse = mean_squared_error(y_test, y_predictions)\n",
    "print(f'The r^2 is: {r2} and the RMSE is: {rmse}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date        Low       Open     Volume       High      Close  \\\n",
      "0  02-01-2015  68.010002  69.000000  4218700.0  71.999001  70.400002   \n",
      "1  05-01-2015  67.059998  71.230003  4534700.0  71.300003  67.629997   \n",
      "2  06-01-2015  63.020000  67.930000  3749400.0  67.989998  64.669998   \n",
      "3  07-01-2015  63.509998  65.010002  2122600.0  66.760002  66.650002   \n",
      "4  08-01-2015  67.129997  67.949997  2510300.0  69.690002  67.690002   \n",
      "\n",
      "   Adjusted Close company_id  \n",
      "0       70.400002       QRVO  \n",
      "1       67.629997       QRVO  \n",
      "2       64.669998       QRVO  \n",
      "3       66.650002       QRVO  \n",
      "4       67.690002       QRVO  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2397141"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "print(df.head())\n",
    "id_df = df.query('Close < 50')\n",
    "id_df.head()\n",
    "len(id_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Size Top Ten Percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the df by size to speed up computation\n",
    "# get volume * open\n",
    "# get avg of that by company, make a new dataframe with only one row per company\n",
    "# plot x-axis as company name and \"avg size\" as y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Blake Dennett\\AppData\\Local\\Temp\\ipykernel_26772\\633171396.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_ten_df['size'] = top_ten_df.apply(lambda x: round((x.Volume * x.Open) / 1000, 2), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>company_id</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>05-11-2019</td>\n",
       "      <td>100.001999</td>\n",
       "      <td>100.150002</td>\n",
       "      <td>3134100.0</td>\n",
       "      <td>101.849998</td>\n",
       "      <td>101.300003</td>\n",
       "      <td>101.300003</td>\n",
       "      <td>QRVO</td>\n",
       "      <td>313880.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>06-11-2019</td>\n",
       "      <td>100.220001</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>3153300.0</td>\n",
       "      <td>102.309998</td>\n",
       "      <td>101.400002</td>\n",
       "      <td>101.400002</td>\n",
       "      <td>QRVO</td>\n",
       "      <td>317726.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>07-11-2019</td>\n",
       "      <td>100.879997</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>2482500.0</td>\n",
       "      <td>102.879997</td>\n",
       "      <td>101.309998</td>\n",
       "      <td>101.309998</td>\n",
       "      <td>QRVO</td>\n",
       "      <td>253215.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>08-11-2019</td>\n",
       "      <td>101.750000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>2867000.0</td>\n",
       "      <td>104.220001</td>\n",
       "      <td>104.040001</td>\n",
       "      <td>104.040001</td>\n",
       "      <td>QRVO</td>\n",
       "      <td>292434.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>11-11-2019</td>\n",
       "      <td>101.930000</td>\n",
       "      <td>103.419998</td>\n",
       "      <td>2181500.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>102.290001</td>\n",
       "      <td>102.290001</td>\n",
       "      <td>QRVO</td>\n",
       "      <td>225610.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Low        Open     Volume        High       Close  \\\n",
       "1219  05-11-2019  100.001999  100.150002  3134100.0  101.849998  101.300003   \n",
       "1220  06-11-2019  100.220001  100.760002  3153300.0  102.309998  101.400002   \n",
       "1221  07-11-2019  100.879997  102.000000  2482500.0  102.879997  101.309998   \n",
       "1222  08-11-2019  101.750000  102.000000  2867000.0  104.220001  104.040001   \n",
       "1223  11-11-2019  101.930000  103.419998  2181500.0  104.000000  102.290001   \n",
       "\n",
       "      Adjusted Close company_id       size  \n",
       "1219      101.300003       QRVO  313880.12  \n",
       "1220      101.400002       QRVO  317726.51  \n",
       "1221      101.309998       QRVO  253215.00  \n",
       "1222      104.040001       QRVO  292434.00  \n",
       "1223      102.290001       QRVO  225610.73  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_df = df.query('Open > 100')\n",
    "top_ten_df.drop(columns=['Date', 'Adjusted Close', 'Low', 'High', 'Close'])\n",
    "top_ten_df['size'] = top_ten_df.apply(lambda x: round((x.Volume * x.Open) / 1000, 2), axis=1)\n",
    "# top_ten_df['size'] = top_ten_df.apply(lambda x: round(x.size, 2), axis=1)\n",
    "top_ten_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
